{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n#import numpy for number array handling and represent rgb image pixel values\nimport numpy as np\n\n#import tensorflow to use any tools needed for deep learning\nimport tensorflow as tf\n\n#import keras api needed to implement deep learning techiques\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#import libraries for visualization of data\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n#Allow charts and graphics to display right below the page of browser setup\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-10T17:19:14.645284Z","iopub.execute_input":"2021-12-10T17:19:14.645615Z","iopub.status.idle":"2021-12-10T17:19:19.533470Z","shell.execute_reply.started":"2021-12-10T17:19:14.645534Z","shell.execute_reply":"2021-12-10T17:19:19.532726Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Download data**","metadata":{}},{"cell_type":"code","source":"#paths to the train, validation and test image datasets \ntrain_path = '../input/garbage-classification/garbage classification/Garbage classification'\nvalid_path = '../input/garbage-classification/garbage classification/Garbage classification'","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:19.535282Z","iopub.execute_input":"2021-12-10T17:19:19.535565Z","iopub.status.idle":"2021-12-10T17:19:19.544079Z","shell.execute_reply.started":"2021-12-10T17:19:19.535527Z","shell.execute_reply":"2021-12-10T17:19:19.539635Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Set up for Generic CNN model**","metadata":{}},{"cell_type":"code","source":"labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n\nfor label in labels:\n    directory = os.path.join(train_path, label)\n    print(\"Images of label \\\"\" + label + \"\\\":\\t\", len(os.listdir(directory)))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:19.545668Z","iopub.execute_input":"2021-12-10T17:19:19.546933Z","iopub.status.idle":"2021-12-10T17:19:20.449141Z","shell.execute_reply.started":"2021-12-10T17:19:19.546890Z","shell.execute_reply":"2021-12-10T17:19:20.448430Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# plotting images of different review for understanding the dataset\n\nplt.figure(figsize=(30,14))\n\nfor i in range(6):\n    directory = os.path.join(train_path, labels[i])\n    for j in range(10):\n        path = os.path.join(directory, os.listdir(directory)[j])\n        img = mpimg.imread(path)\n        \n        plt.subplot(6, 10, i*10 + j + 1)\n        plt.imshow(img)\n        \n        if j == 0:\n            plt.ylabel(labels[i], fontsize=20)\n        \nplt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:20.450537Z","iopub.execute_input":"2021-12-10T17:19:20.450797Z","iopub.status.idle":"2021-12-10T17:19:25.855171Z","shell.execute_reply.started":"2021-12-10T17:19:20.450763Z","shell.execute_reply":"2021-12-10T17:19:25.854233Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# checking size of individual image\n\ndirectory = os.path.join(train_path, 'cardboard')\npath = os.path.join(directory, os.listdir(directory)[0])\nimage = mpimg.imread(path)\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:25.857744Z","iopub.execute_input":"2021-12-10T17:19:25.858028Z","iopub.status.idle":"2021-12-10T17:19:25.873376Z","shell.execute_reply.started":"2021-12-10T17:19:25.857991Z","shell.execute_reply":"2021-12-10T17:19:25.872648Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# creating the model\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(384, 512, 3)),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Dropout(0.2),\n    \n  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Dropout(0.2),\n    \n  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Dropout(0.2),\n\n  tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Dropout(0.2),\n    \n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(512, activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.Dropout(0.4),\n  tf.keras.layers.Dense(6, activation='softmax')\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:25.874784Z","iopub.execute_input":"2021-12-10T17:19:25.875244Z","iopub.status.idle":"2021-12-10T17:19:28.526713Z","shell.execute_reply.started":"2021-12-10T17:19:25.875200Z","shell.execute_reply":"2021-12-10T17:19:28.526082Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(lr = 0.0001), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:28.527948Z","iopub.execute_input":"2021-12-10T17:19:28.528205Z","iopub.status.idle":"2021-12-10T17:19:28.544360Z","shell.execute_reply.started":"2021-12-10T17:19:28.528170Z","shell.execute_reply":"2021-12-10T17:19:28.542803Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# creating generators for combining data and increasing the gainable insights by slightly modifying the images in the dataset\n\ntrain_datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,\n                                   rotation_range=15,zoom_range=0.1,\n                                   width_shift_range=0.15,height_shift_range=0.15,\n                                   shear_range=0.1,\n                                   fill_mode=\"nearest\",\n                                   rescale=1./255., \n                                   validation_split=0.2)\n\ntrain_generator = train_datagen.flow_from_directory(train_path, target_size=(384, 512), batch_size=32, class_mode='binary', subset='training')\nvalidation_generator = train_datagen.flow_from_directory(train_path, target_size=(384, 512), batch_size=32, class_mode='binary', subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:28.546829Z","iopub.execute_input":"2021-12-10T17:19:28.547069Z","iopub.status.idle":"2021-12-10T17:19:28.870609Z","shell.execute_reply.started":"2021-12-10T17:19:28.547039Z","shell.execute_reply":"2021-12-10T17:19:28.869611Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, epochs=50, verbose=1, validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:19:28.871734Z","iopub.execute_input":"2021-12-10T17:19:28.871995Z","iopub.status.idle":"2021-12-10T18:58:24.359730Z","shell.execute_reply.started":"2021-12-10T17:19:28.871962Z","shell.execute_reply":"2021-12-10T18:58:24.358955Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"num_epochs = range(1,51)\nplt.plot(num_epochs, history.history['accuracy'], label='Training', c='r')\nplt.plot(num_epochs, history.history['val_accuracy'], label='Validation', c='b')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:24.361613Z","iopub.execute_input":"2021-12-10T18:58:24.361901Z","iopub.status.idle":"2021-12-10T18:58:24.578049Z","shell.execute_reply.started":"2021-12-10T18:58:24.361862Z","shell.execute_reply":"2021-12-10T18:58:24.577379Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"plt.plot(num_epochs,history.history['loss'],c=\"red\",label=\"Training\")\nplt.plot(num_epochs,history.history['val_loss'],c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:24.579347Z","iopub.execute_input":"2021-12-10T18:58:24.579716Z","iopub.status.idle":"2021-12-10T18:58:24.782402Z","shell.execute_reply.started":"2021-12-10T18:58:24.579679Z","shell.execute_reply":"2021-12-10T18:58:24.781740Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Generate training data set**","metadata":{}},{"cell_type":"code","source":"train_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], \n                                                        batch_size=16, subset='training')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:24.783890Z","iopub.execute_input":"2021-12-10T18:58:24.784170Z","iopub.status.idle":"2021-12-10T18:58:24.999297Z","shell.execute_reply.started":"2021-12-10T18:58:24.784123Z","shell.execute_reply":"2021-12-10T18:58:24.998519Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Generating validatoin data set**","metadata":{}},{"cell_type":"code","source":"valid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n    validation_split=0.2).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:25.000488Z","iopub.execute_input":"2021-12-10T18:58:25.003228Z","iopub.status.idle":"2021-12-10T18:58:25.111151Z","shell.execute_reply.started":"2021-12-10T18:58:25.003198Z","shell.execute_reply":"2021-12-10T18:58:25.110447Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**View the preprocessed picture**","metadata":{}},{"cell_type":"code","source":"def plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:25.114877Z","iopub.execute_input":"2021-12-10T18:58:25.115070Z","iopub.status.idle":"2021-12-10T18:58:25.122516Z","shell.execute_reply.started":"2021-12-10T18:58:25.115046Z","shell.execute_reply":"2021-12-10T18:58:25.121678Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"imgs, labels = next(train_batches)\nplotImages(imgs)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:25.124572Z","iopub.execute_input":"2021-12-10T18:58:25.124884Z","iopub.status.idle":"2021-12-10T18:58:25.824270Z","shell.execute_reply.started":"2021-12-10T18:58:25.124844Z","shell.execute_reply":"2021-12-10T18:58:25.823572Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Build a convolutional neural network**","metadata":{}},{"cell_type":"code","source":"#imput image size\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#Import the pretrained weights VGG basic model\nbase_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:25.825489Z","iopub.execute_input":"2021-12-10T18:58:25.825920Z","iopub.status.idle":"2021-12-10T18:58:26.797287Z","shell.execute_reply.started":"2021-12-10T18:58:25.825881Z","shell.execute_reply":"2021-12-10T18:58:26.796504Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:26.798595Z","iopub.execute_input":"2021-12-10T18:58:26.798868Z","iopub.status.idle":"2021-12-10T18:58:26.816110Z","shell.execute_reply.started":"2021-12-10T18:58:26.798831Z","shell.execute_reply":"2021-12-10T18:58:26.815444Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**Add layers to the model and build the model**","metadata":{}},{"cell_type":"code","source":"\nmodel = Sequential()\n\nbase_model.trainable=False\n\n#Load the pretrained model\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:26.817690Z","iopub.execute_input":"2021-12-10T18:58:26.817956Z","iopub.status.idle":"2021-12-10T18:58:26.934448Z","shell.execute_reply.started":"2021-12-10T18:58:26.817923Z","shell.execute_reply":"2021-12-10T18:58:26.933785Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Set the loss functions、metrics、adam（The initial learning rate 0.0001）**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:26.935520Z","iopub.execute_input":"2021-12-10T18:58:26.935761Z","iopub.status.idle":"2021-12-10T18:58:26.945307Z","shell.execute_reply.started":"2021-12-10T18:58:26.935726Z","shell.execute_reply":"2021-12-10T18:58:26.944530Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=20, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T18:58:26.946419Z","iopub.execute_input":"2021-12-10T18:58:26.947014Z","iopub.status.idle":"2021-12-10T19:08:45.098363Z","shell.execute_reply.started":"2021-12-10T18:58:26.946924Z","shell.execute_reply":"2021-12-10T19:08:45.097603Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"loss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss']","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:08:45.099681Z","iopub.execute_input":"2021-12-10T19:08:45.099990Z","iopub.status.idle":"2021-12-10T19:08:45.104444Z","shell.execute_reply.started":"2021-12-10T19:08:45.099950Z","shell.execute_reply":"2021-12-10T19:08:45.103589Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"accuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:08:45.105658Z","iopub.execute_input":"2021-12-10T19:08:45.106165Z","iopub.status.idle":"2021-12-10T19:08:45.116906Z","shell.execute_reply.started":"2021-12-10T19:08:45.106130Z","shell.execute_reply":"2021-12-10T19:08:45.116156Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(validation_accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:08:45.118266Z","iopub.execute_input":"2021-12-10T19:08:45.118587Z","iopub.status.idle":"2021-12-10T19:08:45.129729Z","shell.execute_reply.started":"2021-12-10T19:08:45.118551Z","shell.execute_reply":"2021-12-10T19:08:45.128990Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Fine-tune model**","metadata":{}},{"cell_type":"code","source":"base_model.trainable=True","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:08:45.132145Z","iopub.execute_input":"2021-12-10T19:08:45.133433Z","iopub.status.idle":"2021-12-10T19:08:45.139415Z","shell.execute_reply.started":"2021-12-10T19:08:45.133385Z","shell.execute_reply":"2021-12-10T19:08:45.138638Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:08:45.140674Z","iopub.execute_input":"2021-12-10T19:08:45.141021Z","iopub.status.idle":"2021-12-10T19:08:45.156958Z","shell.execute_reply.started":"2021-12-10T19:08:45.140986Z","shell.execute_reply":"2021-12-10T19:08:45.156070Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model_details = model.fit(x=train_batches,validation_data=valid_batches,\n                          epochs=8, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:08:45.157961Z","iopub.execute_input":"2021-12-10T19:08:45.158242Z","iopub.status.idle":"2021-12-10T19:12:55.283078Z","shell.execute_reply.started":"2021-12-10T19:08:45.158208Z","shell.execute_reply":"2021-12-10T19:12:55.282203Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model.save('vgg16.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:55.284574Z","iopub.execute_input":"2021-12-10T19:12:55.284862Z","iopub.status.idle":"2021-12-10T19:12:55.426202Z","shell.execute_reply.started":"2021-12-10T19:12:55.284826Z","shell.execute_reply":"2021-12-10T19:12:55.425410Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**View training results**","metadata":{}},{"cell_type":"code","source":"loss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:55.427626Z","iopub.execute_input":"2021-12-10T19:12:55.427885Z","iopub.status.idle":"2021-12-10T19:12:55.432728Z","shell.execute_reply.started":"2021-12-10T19:12:55.427852Z","shell.execute_reply":"2021-12-10T19:12:55.431802Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"len(validation_accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:55.434380Z","iopub.execute_input":"2021-12-10T19:12:55.434967Z","iopub.status.idle":"2021-12-10T19:12:55.446331Z","shell.execute_reply.started":"2021-12-10T19:12:55.434933Z","shell.execute_reply":"2021-12-10T19:12:55.445587Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:55.447831Z","iopub.execute_input":"2021-12-10T19:12:55.448010Z","iopub.status.idle":"2021-12-10T19:12:55.796872Z","shell.execute_reply.started":"2021-12-10T19:12:55.447989Z","shell.execute_reply":"2021-12-10T19:12:55.796170Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:55.798032Z","iopub.execute_input":"2021-12-10T19:12:55.798920Z","iopub.status.idle":"2021-12-10T19:12:56.148297Z","shell.execute_reply.started":"2021-12-10T19:12:55.798874Z","shell.execute_reply":"2021-12-10T19:12:56.147631Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RESNET50**","metadata":{}},{"cell_type":"code","source":"##RESNET50","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:56.149459Z","iopub.execute_input":"2021-12-10T19:12:56.149829Z","iopub.status.idle":"2021-12-10T19:12:56.153904Z","shell.execute_reply.started":"2021-12-10T19:12:56.149786Z","shell.execute_reply":"2021-12-10T19:12:56.153028Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:56.155600Z","iopub.execute_input":"2021-12-10T19:12:56.156177Z","iopub.status.idle":"2021-12-10T19:12:56.370555Z","shell.execute_reply.started":"2021-12-10T19:12:56.156140Z","shell.execute_reply":"2021-12-10T19:12:56.369846Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"valid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n    validation_split=0.2).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:56.371649Z","iopub.execute_input":"2021-12-10T19:12:56.374749Z","iopub.status.idle":"2021-12-10T19:12:56.482337Z","shell.execute_reply.started":"2021-12-10T19:12:56.374699Z","shell.execute_reply":"2021-12-10T19:12:56.481694Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:56.484704Z","iopub.execute_input":"2021-12-10T19:12:56.484972Z","iopub.status.idle":"2021-12-10T19:12:56.490588Z","shell.execute_reply.started":"2021-12-10T19:12:56.484938Z","shell.execute_reply":"2021-12-10T19:12:56.489650Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"imgs, labels = next(train_batches)\nplotImages(imgs)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:56.492008Z","iopub.execute_input":"2021-12-10T19:12:56.492559Z","iopub.status.idle":"2021-12-10T19:12:57.419261Z","shell.execute_reply.started":"2021-12-10T19:12:56.492522Z","shell.execute_reply":"2021-12-10T19:12:57.418601Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#imput image size\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#Import the pretrained weights VGG basic model\nbase_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:57.420587Z","iopub.execute_input":"2021-12-10T19:12:57.421107Z","iopub.status.idle":"2021-12-10T19:12:59.252738Z","shell.execute_reply.started":"2021-12-10T19:12:57.421061Z","shell.execute_reply":"2021-12-10T19:12:59.252000Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:59.254287Z","iopub.execute_input":"2021-12-10T19:12:59.254573Z","iopub.status.idle":"2021-12-10T19:12:59.344809Z","shell.execute_reply.started":"2021-12-10T19:12:59.254539Z","shell.execute_reply":"2021-12-10T19:12:59.343982Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nbase_model.trainable=False\n\n#Load the pretrained model\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:59.345993Z","iopub.execute_input":"2021-12-10T19:12:59.346212Z","iopub.status.idle":"2021-12-10T19:12:59.793910Z","shell.execute_reply.started":"2021-12-10T19:12:59.346187Z","shell.execute_reply":"2021-12-10T19:12:59.793014Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:59.797062Z","iopub.execute_input":"2021-12-10T19:12:59.797287Z","iopub.status.idle":"2021-12-10T19:12:59.810988Z","shell.execute_reply.started":"2021-12-10T19:12:59.797262Z","shell.execute_reply":"2021-12-10T19:12:59.810165Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=20, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:12:59.817119Z","iopub.execute_input":"2021-12-10T19:12:59.817321Z","iopub.status.idle":"2021-12-10T19:23:19.341815Z","shell.execute_reply.started":"2021-12-10T19:12:59.817296Z","shell.execute_reply":"2021-12-10T19:23:19.341008Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"loss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss']","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:23:19.343323Z","iopub.execute_input":"2021-12-10T19:23:19.343560Z","iopub.status.idle":"2021-12-10T19:23:19.348714Z","shell.execute_reply.started":"2021-12-10T19:23:19.343527Z","shell.execute_reply":"2021-12-10T19:23:19.347660Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"accuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:23:19.350182Z","iopub.execute_input":"2021-12-10T19:23:19.350592Z","iopub.status.idle":"2021-12-10T19:23:19.360182Z","shell.execute_reply.started":"2021-12-10T19:23:19.350556Z","shell.execute_reply":"2021-12-10T19:23:19.359271Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"base_model.trainable=True","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:23:19.361522Z","iopub.execute_input":"2021-12-10T19:23:19.362309Z","iopub.status.idle":"2021-12-10T19:23:19.374941Z","shell.execute_reply.started":"2021-12-10T19:23:19.362272Z","shell.execute_reply":"2021-12-10T19:23:19.374239Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:23:19.376276Z","iopub.execute_input":"2021-12-10T19:23:19.376527Z","iopub.status.idle":"2021-12-10T19:23:19.403999Z","shell.execute_reply.started":"2021-12-10T19:23:19.376495Z","shell.execute_reply":"2021-12-10T19:23:19.403306Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model_details = model.fit(x=train_batches,validation_data=valid_batches,\n                          epochs=8, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:23:19.405041Z","iopub.execute_input":"2021-12-10T19:23:19.405287Z","iopub.status.idle":"2021-12-10T19:27:20.629579Z","shell.execute_reply.started":"2021-12-10T19:23:19.405254Z","shell.execute_reply":"2021-12-10T19:27:20.628827Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model.save('ResNet50.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:27:20.631229Z","iopub.execute_input":"2021-12-10T19:27:20.631493Z","iopub.status.idle":"2021-12-10T19:27:21.093149Z","shell.execute_reply.started":"2021-12-10T19:27:20.631457Z","shell.execute_reply":"2021-12-10T19:27:21.092296Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"loss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:27:21.094562Z","iopub.execute_input":"2021-12-10T19:27:21.094870Z","iopub.status.idle":"2021-12-10T19:27:21.100704Z","shell.execute_reply.started":"2021-12-10T19:27:21.094834Z","shell.execute_reply":"2021-12-10T19:27:21.099951Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:27:21.102526Z","iopub.execute_input":"2021-12-10T19:27:21.103083Z","iopub.status.idle":"2021-12-10T19:27:21.423341Z","shell.execute_reply.started":"2021-12-10T19:27:21.103040Z","shell.execute_reply":"2021-12-10T19:27:21.422616Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:27:21.424442Z","iopub.execute_input":"2021-12-10T19:27:21.424693Z","iopub.status.idle":"2021-12-10T19:27:21.751330Z","shell.execute_reply.started":"2021-12-10T19:27:21.424659Z","shell.execute_reply":"2021-12-10T19:27:21.750632Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**VGG19**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n\n\n\n\nvalid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n    validation_split=0.2).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')\n\n\ndef plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nimgs, labels = next(train_batches)\nplotImages(imgs)\n\n\n#imput image size\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#Import the pretrained weights VGG basic model\nbase_model = tf.keras.applications.VGG19(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')\n\n\nbase_model.summary()\n\n\nmodel = Sequential()\n\nbase_model.trainable=False\n\n#Load the pretrained model\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=20, verbose=2)\n\nloss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss'] \n\n\naccuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']\n\nbase_model.trainable=True\n\nmodel.summary()\n\nmodel_details = model.fit(x=train_batches,validation_data=valid_batches,\n                          epochs=8, verbose=2)\n\n\nmodel.save('vgg19.h5')\n\n\nloss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])\n\n\nprint(\"Epochs vs Validation Graph\")\nepochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()\n\nprint(\"Epochs vs Accuracy Graph\")\nepochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:27:21.753469Z","iopub.execute_input":"2021-12-10T19:27:21.754050Z","iopub.status.idle":"2021-12-10T19:42:00.050006Z","shell.execute_reply.started":"2021-12-10T19:27:21.754008Z","shell.execute_reply":"2021-12-10T19:42:00.048734Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MobileNet**","metadata":{}},{"cell_type":"code","source":"train_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n\n\n\n\nvalid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,\n    validation_split=0.2).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')\n\n\ndef plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nimgs, labels = next(train_batches)\nplotImages(imgs)\n\n\n#imput image size\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#Import the pretrained weights VGG basic model\nbase_model = tf.keras.applications.MobileNet(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')\n\n\nbase_model.summary()\n\n\nmodel = Sequential()\n\nbase_model.trainable=False\n\n#Load the pretrained model\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=20, verbose=2)\n\nloss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss'] \n\n\naccuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']\n\nbase_model.trainable=True\n\nmodel.summary()\n\nmodel_details = model.fit(x=train_batches,validation_data=valid_batches,\n                          epochs=8, verbose=2)\n\n\nmodel.save('vgg19.h5')\n\n\nloss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])\n\n\nprint(\"Epochs vs Validation loss graph\")\nepochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()\n\nprint(\"Epochs vs Accuracy Graph\")\nepochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:42:00.051691Z","iopub.execute_input":"2021-12-10T19:42:00.052156Z","iopub.status.idle":"2021-12-10T19:55:59.760010Z","shell.execute_reply.started":"2021-12-10T19:42:00.052095Z","shell.execute_reply":"2021-12-10T19:55:59.759265Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.densenet.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n\n\n\n\nvalid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.densenet.preprocess_input,\n    validation_split=0.2).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')\n\n\ndef plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nimgs, labels = next(train_batches)\nplotImages(imgs)\n\n\n#imput image size\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#Import the pretrained weights Densenet121 basic model\nbase_model = tf.keras.applications.DenseNet121(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')\n\n\nbase_model.summary()\n\n\nmodel = Sequential()\n\nbase_model.trainable=False\n\n#Load the pretrained model\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=20, verbose=2)\n\nloss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss'] \n\n\naccuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']\n\nbase_model.trainable=True\n\nmodel.summary()\n\nmodel_details = model.fit(x=train_batches,validation_data=valid_batches,\n                          epochs=8, verbose=2)\n\n\nmodel.save('DenseNet121.h5')\n\n\nloss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])\n\nprint(\"Epochs vs Validation loss graph\")\nepochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()\n\nprint(\"Epochs vs Accuracy Graph\")\nepochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:55:59.761491Z","iopub.execute_input":"2021-12-10T19:55:59.761746Z","iopub.status.idle":"2021-12-10T20:10:43.062263Z","shell.execute_reply.started":"2021-12-10T19:55:59.761710Z","shell.execute_reply":"2021-12-10T20:10:43.061573Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.xception.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n\n\n\n\nvalid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.xception.preprocess_input,\n    validation_split=0.2).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')\n\n\ndef plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nimgs, labels = next(train_batches)\nplotImages(imgs)\n\n\n#imput image size\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#Import the pretrained weights VGG basic model\nbase_model = tf.keras.applications.Xception(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')\n\n\nbase_model.summary()\n\n\nmodel = Sequential()\n\nbase_model.trainable=True\n\n#Load the pretrained model\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=20, verbose=2)\n\nloss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss'] \n\n\naccuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']\n\nprint(\"Epochs vs Validation loss graph\")\nepochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()\n\nprint(\"Epochs vs Accuracy Graph\")\nepochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T20:10:43.063820Z","iopub.execute_input":"2021-12-10T20:10:43.064281Z","iopub.status.idle":"2021-12-10T20:24:01.445601Z","shell.execute_reply.started":"2021-12-10T20:10:43.064243Z","shell.execute_reply":"2021-12-10T20:24:01.444915Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"### Mobilenet","metadata":{"execution":{"iopub.status.busy":"2021-12-10T20:24:01.446733Z","iopub.execute_input":"2021-12-10T20:24:01.447388Z","iopub.status.idle":"2021-12-10T20:24:01.451427Z","shell.execute_reply.started":"2021-12-10T20:24:01.447343Z","shell.execute_reply":"2021-12-10T20:24:01.450607Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train_batches = ImageDataGenerator(\n    rescale = 1./255,\n    shear_range=0.1,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=0.1,\n    horizontal_flip=True,\n    vertical_flip=True).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n\n\n\n\nvalid_batches = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.1).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')\n\n\ndef plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nimgs, labels = next(train_batches)\nplotImages(imgs)\n\n\n#imput image size\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#Import the pretrained weights VGG basic model\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')\n\n\nbase_model.summary()\n\n\nmodel = Sequential()\n\nbase_model.trainable=False\n\n#Load the pretrained model\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=20, verbose=2)\n\nloss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss'] \n\n\naccuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']\n\nbase_model.trainable=True\n\nmodel.summary()\n\nmodel_details = model.fit(x=train_batches,validation_data=valid_batches,\n                          epochs=8, verbose=2)\n\n\nmodel.save('DenseNet121.h5')\n\n\nloss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])\n\nprint(\"Epochs vs Validation Loss graph\")\nepochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()\n\nprint(\"Epochs vs Accuracy graph\")\nepochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T20:24:01.452850Z","iopub.execute_input":"2021-12-10T20:24:01.453096Z","iopub.status.idle":"2021-12-10T20:38:35.772470Z","shell.execute_reply.started":"2021-12-10T20:24:01.453061Z","shell.execute_reply":"2021-12-10T20:38:35.771789Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}